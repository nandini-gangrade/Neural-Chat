# NeuralChat â€” Full-Stack AI RAG Chatbot

> **Tech Stack:** FastAPI Â· LangChain Â· ChromaDB Â· OpenAI/Azure Â· React.js  
> **Type:** RAG (Retrieval Augmented Generation) AI Chatbot  
> **Demo-ready for:** Hackathons Â· Technical Interviews Â· TCS Presentations

---

## Project Structure

```
NeuralChat/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py              â† FastAPI app (main entry point)
â”‚   â”œâ”€â”€ llm.py              â† LLM call wrapper (LangChain + OpenAI)
â”‚   â”œâ”€â”€ vector.py           â† Document ingestion, chunking, ChromaDB queries
â”‚   â”œâ”€â”€ strings.py          â† System prompts and string constants
â”‚   â”œâ”€â”€ sample.txt          â† Sample document for testing
â”‚   â”œâ”€â”€ requirements.txt    â† Python dependencies
â”‚   â”œâ”€â”€ start.sh            â† Backend startup script
â”‚   â”œâ”€â”€ .env                â† ðŸ”‘ ADD YOUR CREDENTIALS HERE
â”‚   â”œâ”€â”€ chroma_db/          â† Persisted ChromaDB vector store
â”‚   â”‚   â””â”€â”€ chroma.sqlite3
â”‚   â””â”€â”€ tiktoken_cache/     â† Local tokenizer cache (offline support)
â”‚       â””â”€â”€ 9b5ad71b...
â”‚
â””â”€â”€ frontend/
    â”œâ”€â”€ public/
    â”‚   â””â”€â”€ index.html
    â”œâ”€â”€ src/
    â”‚   â”œâ”€â”€ pages/
    â”‚   â”‚   â”œâ”€â”€ Login.jsx       â† Login page (mock auth)
    â”‚   â”‚   â”œâ”€â”€ Register.jsx    â† Registration page
    â”‚   â”‚   â””â”€â”€ Chat.jsx        â† Main chatbot interface
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ Navbar.jsx       â† Top navigation bar
    â”‚   â”‚   â”œâ”€â”€ ChatBubble.jsx   â† Individual message bubble
    â”‚   â”‚   â””â”€â”€ UploadModal.jsx  â† Document upload modal
    â”‚   â”œâ”€â”€ services/
    â”‚   â”‚   â”œâ”€â”€ api.js           â† All API calls centralized
    â”‚   â”‚   â””â”€â”€ auth.js          â† Mock auth logic
    â”‚   â”œâ”€â”€ App.jsx              â† Router + route guards
    â”‚   â”œâ”€â”€ index.js             â† React entry point
    â”‚   â””â”€â”€ index.css            â† Global styles + CSS variables
    â””â”€â”€ package.json
```

---

## Step 1 â€” Add Your Credentials

Edit `backend/.env`:

```env
API_ENDPOINT="https://your-resource.openai.azure.com/"
API_KEY="your-api-key-here"
LLM_MODEL="azure/genailab-maas-gpt-4.1"
EMBEDDING_MODEL="azure/genailab-maas-text-embedding-3-large"
VERIFY_SSL=false
```

> `VERIFY_SSL=false` disables SSL verification â€” needed for corporate proxies.

---

## Step 2 â€” Start the Backend

```bash
cd backend

# Install dependencies
pip install -r requirements.txt

# Start the server
uvicorn api:app --host 0.0.0.0 --port 8000 --reload

# Or use the script
bash start.sh
```

Backend runs at: **http://localhost:8000**  
Swagger UI at:   **http://localhost:8000/docs**

---

## Step 3 â€” Start the Frontend

```bash
cd frontend

# Install dependencies
npm install

# Start development server
npm start
```

Frontend runs at: **http://localhost:3000**

---

## How Authentication Works

Authentication is **fully frontend-based (mock)** â€” no backend required.

| Step | What happens |
|---|---|
| Register | User `{ name, email, password }` saved to `localStorage['nc_users']` |
| Login | Credentials checked against `localStorage['nc_users']` |
| Session | `{ name, email }` object saved to `localStorage['nc_session']` |
| Route guard | `App.jsx` reads `nc_session` â€” redirects to `/login` if absent |
| Logout | `nc_session` removed from `localStorage` |

**Default demo account** (auto-seeded):
- Email: `demo@neuralchat.ai`
- Password: `demo1234`

---

## How RAG Works (Backend Flow)

```
User Query
    â”‚
    â–¼
POST /api/query { "query": "..." }
    â”‚
    â”œâ”€â–º query_chroma_db()
    â”‚       Embeds query â†’ similarity search in ChromaDB
    â”‚       Returns top-5 most relevant document chunks
    â”‚
    â””â”€â–º generate_answer()
            Builds prompt: context + query
            Calls LLM â†’ returns grounded answer
    â”‚
    â–¼
{ "answer": "...", "docs": [...], "sources_count": 5 }
```

---

## API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| GET | `/` | Health check (root) |
| GET | `/health` | JSON health check |
| POST | `/api/query` | RAG query â€” vector search + LLM answer |
| POST | `/api/llm` | Direct LLM call (no retrieval) |
| POST | `/api/ingest` | Upload & ingest a document into ChromaDB |

### POST /api/query
```json
// Request
{ "query": "What is the net profit for Q4?" }

// Response
{
  "answer": "Based on the context...",
  "docs": ["chunk1...", "chunk2..."],
  "sources_count": 5
}
```

### POST /api/ingest
Send as `multipart/form-data` with field `file`.  
Accepts: `.txt`, `.pdf`, `.docx`, `.doc`

---

## What Was Fixed From Original Code

| File | Issue | Fix |
|------|-------|-----|
| `vector.py` | Line 105 had orphaned code `vectors = embedding_model.embed_documents(...)` outside any function â€” **syntax error** | Removed orphaned line |
| `vector.py` | Used `langchain_community.vectorstores.Chroma` (deprecated) | Updated to `langchain_chroma.Chroma` |
| `vector.py` | `store_embeddings` called `vectorstore.persist()` which is deprecated in new LangChain | Removed deprecated call |
| `vector.py` | Hardcoded relative paths for chroma_db | Made paths relative to `__file__` so they work from any working directory |
| `llm.py` | `VERIFY_SSL` not read from env | Added env-based SSL toggle |
| `api.py` | No health check, no ingest endpoint | Added `/health` and `/api/ingest` |
| `requirements.txt` | Duplicates, missing packages | Cleaned and added `fastapi`, `uvicorn`, `langchain-chroma`, `python-multipart` |

---

## Frontend Features

- **Login / Register** â€” mock auth with localStorage, animated forms
- **Chat interface** â€” animated message bubbles, typing indicator, auto-scroll
- **Sidebar** â€” live backend status, mode toggle (RAG vs Direct LLM), query suggestions
- **Upload modal** â€” drag-and-drop document ingestion into ChromaDB
- **Source count badge** â€” shows how many document chunks were retrieved
- **Error handling** â€” clear error messages if backend is down
- **Route protection** â€” unauthenticated users redirected to `/login`
- **Responsive input** â€” auto-expanding textarea, Enter to send

---

## Troubleshooting

**CORS error?**  
Make sure the backend's CORS middleware allows `http://localhost:3000` (already configured in `api.py`).

**Backend not starting?**  
Ensure all packages are installed: `pip install -r requirements.txt`

**ChromaDB error?**  
The `chroma_db/` folder is already included with pre-existing embeddings. If you want to re-ingest documents, use the Upload button in the UI or call `POST /api/ingest`.

**SSL error?**  
Set `VERIFY_SSL=false` in your `.env` file.

**tiktoken error?**  
The `tiktoken_cache/` folder is bundled â€” tokenizer works offline. If missing, run:  
`TIKTOKEN_CACHE_DIR=./tiktoken_cache python -c "import tiktoken; tiktoken.get_encoding('cl100k_base')"`
